# 微博爬虫可视化工具

## 项目简介

本项目基于 [dataabc/weiboSpider](https://github.com/dataabc/weiboSpider) 开发，为原始的命令行微博爬虫工具提供了友好的图形用户界面，让普通用户可以通过可视化界面轻松配置和运行微博数据爬取任务。

## 🚀 主要特性

- **🖥️ 可视化界面**: 基于tkinter的现代化GUI界面
- **⚙️ 参数配置**: 可视化配置所有爬虫参数，无需编辑配置文件
- **📊 实时日志**: 实时显示爬取进度和运行状态
- **💾 配置管理**: 支持保存和加载配置文件，方便重复使用
- **🎯 一键启动**: 双击批处理文件即可运行
- **📦 可执行文件**: 支持打包成独立的exe文件，无需Python环境
- **🛡️ 错误处理**: 完善的错误提示和异常处理机制

## 📁 项目结构

```
weiboSpider/
├── weibo_spider/              # 原始爬虫核心模块
├── weibo_spider_gui.py        # GUI主程序
├── run_spider.py              # 爬虫运行脚本
├── start_gui.bat              # GUI启动脚本
├── build_exe.py               # 可执行文件构建脚本
├── build_exe.bat              # 构建批处理文件
├── 使用说明.md                 # 详细使用说明
├── README_GUI.md              # 项目说明文档
└── requirements.txt           # 依赖包列表
```

## 🛠️ 安装和运行

### 环境要求

- Python 3.6+
- Windows操作系统（推荐）
- 网络连接

### 快速开始

1. **克隆项目**
   ```bash
   git clone https://github.com/dataabc/weiboSpider.git
   cd weiboSpider
   ```

2. **安装依赖**
   ```bash
   pip install -r requirements.txt
   ```

3. **启动GUI**
   - 方法一：双击 `start_gui.bat`
   - 方法二：运行 `python weibo_spider_gui.py`

### 构建可执行文件

如果您想要创建独立的exe文件：

1. **自动构建**
   ```bash
   # 双击运行
   build_exe.bat
   
   # 或命令行运行
   python build_exe.py
   ```

2. **手动构建**
   ```bash
   pip install pyinstaller
   pyinstaller --onefile --windowed --name=微博爬虫工具 weibo_spider_gui.py
   ```

## 🎮 使用指南

### 界面功能说明

#### 基本配置区域
- **用户ID列表**: 输入要爬取的微博用户ID，多个ID用逗号分隔
- **开始日期**: 爬取的起始日期（格式：YYYY-MM-DD）
- **结束日期**: 爬取的结束日期（可填"now"表示当前时间）
- **微博类型**: 选择爬取全部微博或仅原创微博

#### 下载选项
- **下载图片**: 是否下载微博中的图片文件
- **下载视频**: 是否下载微博中的视频文件

#### 输出格式
- **CSV**: 表格格式，便于数据分析
- **TXT**: 文本格式，便于阅读
- **JSON**: 结构化数据格式

#### Cookie配置
- 必须配置有效的微博Cookie才能正常爬取数据
- 获取方法请参考使用说明文档

#### 输出目录
- 选择爬取结果的保存位置
- 默认为当前目录下的`weibo_data`文件夹

### 操作流程

1. **配置参数** → 填写用户ID、时间范围等基本信息
2. **设置Cookie** → 输入有效的微博登录Cookie
3. **选择选项** → 配置下载选项和输出格式
4. **开始爬取** → 点击"开始爬取"按钮
5. **监控进度** → 在日志区域查看实时进度
6. **查看结果** → 爬取完成后在输出目录查看结果

## 📊 输出结果

爬取完成后，会在指定目录生成以下文件结构：

```
weibo_data/
├── 用户昵称1/
│   ├── 用户ID.csv          # 微博数据CSV格式
│   ├── 用户ID.txt          # 微博数据文本格式
│   ├── 用户ID.json         # 微博数据JSON格式（可选）
│   ├── img/                # 图片文件夹
│   │   ├── 原创/           # 原创微博图片
│   │   └── 转发/           # 转发微博图片
│   └── video/              # 视频文件夹
│       ├── 原创/           # 原创微博视频
│       └── 转发/           # 转发微博视频
└── config.json             # 本次爬取的配置文件
```

## 🔧 高级功能

### 配置文件管理

- **保存配置**: 将当前设置保存为JSON文件，便于重复使用
- **加载配置**: 从之前保存的配置文件快速恢复设置
- **配置模板**: 可以创建不同场景的配置模板

### 批量处理

- 支持同时爬取多个用户的微博数据
- 自动处理用户ID列表
- 智能去重和错误处理

### 安全特性

- Cookie信息加密显示
- 自动检测无效配置
- 完善的错误提示机制

## ⚠️ 注意事项

### 法律合规
- 请遵守相关法律法规，合理使用爬虫工具
- 爬取的数据仅供学习研究使用
- 不要用于商业用途或侵犯他人权益

### 技术限制
- 需要有效的微博Cookie才能正常工作
- 爬取速度受微博反爬机制限制
- 建议合理设置爬取频率，避免被封禁

### 使用建议
- 首次使用建议先爬取少量数据进行测试
- 定期更新Cookie以保持有效性
- 注意磁盘空间，图片和视频文件较大

## 🐛 常见问题

### Q: 程序无法启动
**A**: 检查Python环境和依赖包是否正确安装

### Q: 爬取失败或数据为空
**A**: 通常是Cookie问题，请重新获取有效的Cookie

### Q: 爬取速度很慢
**A**: 这是正常现象，程序内置了防反爬机制

### Q: 如何获取用户ID
**A**: 参考原项目文档中的用户ID获取方法

### Q: 被系统限制怎么办
**A**: 暂停使用一段时间，或调整爬取参数

## 🤝 贡献

欢迎提交Issue和Pull Request来改进这个项目！

### 开发环境设置

1. Fork本项目
2. 创建功能分支
3. 提交更改
4. 创建Pull Request

## 📄 许可证

本项目遵循原项目的许可证条款。

## 🙏 致谢

- 感谢 [dataabc/weiboSpider](https://github.com/dataabc/weiboSpider) 提供的优秀爬虫框架
- 感谢所有为开源项目做出贡献的开发者

## 📞 联系方式

如有问题或建议，请通过以下方式联系：

- 提交GitHub Issue
- 参考原项目的讨论区

---

**免责声明**: 本工具仅供学习和研究使用，使用者需自行承担使用风险，开发者不承担任何法律责任。